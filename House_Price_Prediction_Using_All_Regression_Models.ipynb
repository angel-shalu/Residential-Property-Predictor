{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b4a4747-6428-4d44-82cb-cdccacef5874",
   "metadata": {},
   "source": [
    "**Housing Price Prediction Using Multiple Regression Algorithms and Pickle**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1904dd-dbe1-40f3-aa0a-6fe2090b8f9c",
   "metadata": {},
   "source": [
    "**Introduction**\n",
    "  \n",
    "Today, we are moving a step ahead from individual regression algorithms and learning how to evaluate and compare multiple regression models in one go using a unified structure.\n",
    "\n",
    "So far, we have explored:\n",
    "\n",
    "- Regression models like Linear Regression, Ridge, Lasso, Random Forest, SVM, etc.\n",
    "\n",
    "**In this notebook, we’ll:**\n",
    "\n",
    "- Train and evaluate multiple regression algorithms\n",
    "\n",
    "- Save each trained model as a .pkl file using pickle\n",
    "\n",
    "- Compare their performance using MAE, MSE, and R²\n",
    "\n",
    "- Prepare these models to be used with any frontend like Streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7ea994-5807-48dd-977e-d14f091a5325",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63fb6a30-8b1d-4489-a31e-3f07de3c3ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor, HuberRegressor)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce89343-662b-4025-bf6d-6342eb4a4b6c",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "436e6ba7-6f96-496a-a7c4-54feed705511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg. Area Income</th>\n",
       "      <th>Avg. Area House Age</th>\n",
       "      <th>Avg. Area Number of Rooms</th>\n",
       "      <th>Avg. Area Number of Bedrooms</th>\n",
       "      <th>Area Population</th>\n",
       "      <th>Price</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79545.458574</td>\n",
       "      <td>5.682861</td>\n",
       "      <td>7.009188</td>\n",
       "      <td>4.09</td>\n",
       "      <td>23086.800503</td>\n",
       "      <td>1.059034e+06</td>\n",
       "      <td>208 Michael Ferry Apt. 674\\nLaurabury, NE 3701...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79248.642455</td>\n",
       "      <td>6.002900</td>\n",
       "      <td>6.730821</td>\n",
       "      <td>3.09</td>\n",
       "      <td>40173.072174</td>\n",
       "      <td>1.505891e+06</td>\n",
       "      <td>188 Johnson Views Suite 079\\nLake Kathleen, CA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61287.067179</td>\n",
       "      <td>5.865890</td>\n",
       "      <td>8.512727</td>\n",
       "      <td>5.13</td>\n",
       "      <td>36882.159400</td>\n",
       "      <td>1.058988e+06</td>\n",
       "      <td>9127 Elizabeth Stravenue\\nDanieltown, WI 06482...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63345.240046</td>\n",
       "      <td>7.188236</td>\n",
       "      <td>5.586729</td>\n",
       "      <td>3.26</td>\n",
       "      <td>34310.242831</td>\n",
       "      <td>1.260617e+06</td>\n",
       "      <td>USS Barnett\\nFPO AP 44820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59982.197226</td>\n",
       "      <td>5.040555</td>\n",
       "      <td>7.839388</td>\n",
       "      <td>4.23</td>\n",
       "      <td>26354.109472</td>\n",
       "      <td>6.309435e+05</td>\n",
       "      <td>USNS Raymond\\nFPO AE 09386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Avg. Area Income  Avg. Area House Age  Avg. Area Number of Rooms  \\\n",
       "0      79545.458574             5.682861                   7.009188   \n",
       "1      79248.642455             6.002900                   6.730821   \n",
       "2      61287.067179             5.865890                   8.512727   \n",
       "3      63345.240046             7.188236                   5.586729   \n",
       "4      59982.197226             5.040555                   7.839388   \n",
       "\n",
       "   Avg. Area Number of Bedrooms  Area Population         Price  \\\n",
       "0                          4.09     23086.800503  1.059034e+06   \n",
       "1                          3.09     40173.072174  1.505891e+06   \n",
       "2                          5.13     36882.159400  1.058988e+06   \n",
       "3                          3.26     34310.242831  1.260617e+06   \n",
       "4                          4.23     26354.109472  6.309435e+05   \n",
       "\n",
       "                                             Address  \n",
       "0  208 Michael Ferry Apt. 674\\nLaurabury, NE 3701...  \n",
       "1  188 Johnson Views Suite 079\\nLake Kathleen, CA...  \n",
       "2  9127 Elizabeth Stravenue\\nDanieltown, WI 06482...  \n",
       "3                          USS Barnett\\nFPO AP 44820  \n",
       "4                         USNS Raymond\\nFPO AE 09386  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\Lenovo\\OneDrive\\Desktop\\Python Everyday work\\Github work\\ML_Project\\USA_Housing.csv\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f872bd2e-4e3d-4d7e-b303-a94bb6473f04",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "We drop columns that won't help with prediction (Address is non-numeric), and separate the target (Price)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae8d963a-361e-477a-9572-c0a08af65d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Price', 'Address'], axis=1)\n",
    "y = data['Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d49ec8-1520-4837-906b-0272236909a5",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f54fba7-1c8f-4564-9014-1a07df3801df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a1fc9e-b4ee-49f6-ac4f-15bc3e2cf958",
   "metadata": {},
   "source": [
    "# Scale data for models that require it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "132b7026-a701-4d94-8d88-c0c9445cf1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772745e4-14f4-4309-a94a-f8e389fa53ea",
   "metadata": {},
   "source": [
    "# Define All Regressor Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1422a587-37ab-47f6-88bc-d9727fbfbf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    # Models that need scaled data\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'RobustRegression': HuberRegressor(),\n",
    "    'RidgeRegression': Ridge(),\n",
    "    'LassoRegression': Lasso(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'PolynomialRegression': Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=4)),\n",
    "        ('linear', LinearRegression())\n",
    "    ]),\n",
    "    'SGDRegressor': SGDRegressor(),\n",
    "    'ANN': MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000),\n",
    "    'SVM': SVR(),\n",
    "    'KNN': KNeighborsRegressor(),\n",
    "\n",
    "    # Models that don’t need scaling\n",
    "    'RandomForest': RandomForestRegressor(),\n",
    "    'LGBM': lgb.LGBMRegressor(),\n",
    "    'XGBoost': xgb.XGBRegressor()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd372b8f-f2e3-46e2-a2d3-4a73d0940d60",
   "metadata": {},
   "source": [
    "# Train Models, Evaluate, and Save as .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00b74436-7df8-4743-bab0-7a531025c546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1256\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 1231911.452183\n",
      "All models trained, evaluated, and saved as .pkl files.\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Check if model requires scaling\n",
    "    if name in ['LinearRegression', 'RobustRegression', 'RidgeRegression', 'LassoRegression',\n",
    "                'ElasticNet', 'PolynomialRegression', 'SGDRegressor', 'ANN', 'SVM', 'KNN']:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'MAE': round(mae, 2),\n",
    "        'MSE': round(mse, 2),\n",
    "        'R2': round(r2, 4)\n",
    "    })\n",
    "\n",
    "    # Save model\n",
    "    with open(f'{name}.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "print(\"All models trained, evaluated, and saved as .pkl files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38024e1e-76ec-4cd8-b425-b4431bcbf824",
   "metadata": {},
   "source": [
    "# Show Model Comparison Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6a24e35-bfb0-4e7f-9b4e-f05a91d9f0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Model         MAE           MSE       R2\n",
      "0       RobustRegression    82659.92  1.054623e+10   0.9147\n",
      "1        RidgeRegression    82658.16  1.054893e+10   0.9147\n",
      "2           SGDRegressor    82567.49  1.054623e+10   0.9147\n",
      "3        LassoRegression    82657.87  1.054970e+10   0.9146\n",
      "4       LinearRegression    82657.95  1.054972e+10   0.9146\n",
      "5   PolynomialRegression    84013.48  1.073798e+10   0.9131\n",
      "6                   LGBM    92133.99  1.309771e+10   0.8940\n",
      "7           RandomForest    97709.90  1.473850e+10   0.8808\n",
      "8                XGBoost   101565.19  1.613868e+10   0.8694\n",
      "9                    KNN   105521.78  1.710311e+10   0.8616\n",
      "10            ElasticNet   121396.83  2.288246e+10   0.8149\n",
      "11                   SVM   282858.36  1.234840e+11   0.0009\n",
      "12                   ANN  1175960.23  1.483829e+12 -11.0052\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(by='R2', ascending=False, inplace=True)\n",
    "results_df.reset_index(drop=True, inplace=True)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda7fee9-5904-4419-861b-067e97b30166",
   "metadata": {},
   "source": [
    "# Save Results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c328d841-e3a7-4353-bcfc-204ddbedd107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation saved to model_evaluation_results.csv\n"
     ]
    }
   ],
   "source": [
    "results_df.to_csv('model_evaluation_results.csv', index=False)\n",
    "print(\"Model evaluation saved to model_evaluation_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd481bf-8f79-4f16-945a-78d2e482fc5e",
   "metadata": {},
   "source": [
    "# Final Notes\n",
    "\n",
    "- All models are saved and can be loaded back in Streamlit or any app using pickle.load(open('model.pkl', 'rb')).\n",
    "\n",
    "- This helps you pick the best model for production use based on accuracy (R²), error (MAE), etc.\n",
    "\n",
    "- You can now build a Streamlit app that allows you to upload input and choose a model to predict!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b959c336-3e8c-43dd-ae03-18d60f03ac88",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this project, we developed and compared multiple regression models to predict **housing prices** based on various area-specific features such as average income, house age, number of rooms, number of bedrooms, and area population.\n",
    "\n",
    "After training and evaluating 13 different models, we found the following insights:\n",
    "\n",
    "- **Top Performing Models** (based on low MAE, MSE and high R² Score):\n",
    "  - **SGD Regressor**: Lowest MAE (82,567) and high R² (0.9147)\n",
    "  - **Ridge Regression** and **Robust Regression** closely followed with similar performance and strong generalization.\n",
    "  \n",
    "- **Baseline Models** like **Linear Regression** and **Lasso Regression** performed decently with an R² of **~0.9146**, suggesting the problem is well-suited for linear approaches.\n",
    "\n",
    "- **Polynomial Regression** slightly improved performance but at the cost of increased model complexity.\n",
    "\n",
    "- **Ensemble Models** such as **LGBM** and **Random Forest** performed well but not significantly better than simpler models.\n",
    "\n",
    "- **XGBoost** and **KNN** underperformed compared to others, with higher error values.\n",
    "\n",
    "- **SVM** and **ANN** (Artificial Neural Network) showed **very poor performance**, especially the ANN which had an **R² of -11.0052**, indicating severe overfitting or improper tuning.\n",
    "\n",
    "\n",
    "## Final Recommendation\n",
    "\n",
    "Considering performance and interpretability, **SGD Regressor**, **Ridge Regression**, and **Robust Regression** are the **best choices** for deployment in this use case. These models offer:\n",
    "\n",
    "- High accuracy  \n",
    "- Low error margins  \n",
    "- Better generalization  \n",
    "- Simpler implementation and tuning  \n",
    "\n",
    "## Future Scope\n",
    "\n",
    "- Hyperparameter tuning for all models  \n",
    "- More advanced feature engineering or scaling methods  \n",
    "- Experimenting with stacked models or deep learning (with proper normalization and regularization)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
